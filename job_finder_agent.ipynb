{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c5317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import ollama\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ca115b-f63e-42d3-9c5d-bf5d913ecf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/robinwarden/Desktop/Projects/job-copilot/job-copilot/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9076762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "badd1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Say hello to Robin!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26b25f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d85342e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caaf15a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I don't know who Robin is, but I'm happy to meet you! Is there a Robin you'd like to talk about (e.g. from Batman or another context)? Or would you just like some conversation?\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b64716aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèóÔ∏è Class to represent a job listing webpage\n",
    "\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Job_Platform:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "        # Remove unwanted tags\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8039e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí¨ Build a user prompt from the job listing\n",
    "def user_prompt_for(job_listing):\n",
    "    user_prompt = f\"You are looking at a job listing titled: {job_listing.title}\\n\"\n",
    "    user_prompt += \"The contents of this listing are as follows. Please provide a short summary in markdown format. \\\n",
    "If there are job requirements, duties, or application instructions, highlight them:\\n\\n\"\n",
    "    user_prompt += job_listing.text\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb79c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Send the user/system prompt to OpenAI\n",
    "def ask_ollama(system_prompt, user_prompt, model=MODEL):\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16558a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Load resume from file\n",
    "with open(\"resume.txt\", \"r\") as file:\n",
    "    my_resume = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e37f2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Robin Warden\n",
      "Software Engineer | Frontend & API Developer | AI Automation Enthusiast\n",
      "Lawrenceville, GA       \n",
      "(470) 406-1714     \n",
      "Email| LinkedIn | GitHub | Portfolio\n",
      "\n",
      "+Professional Summary\n",
      "\n",
      "Creative and AI-native Frontend Developer with 3+ years of experience building scalable web and mobile interfaces using React, TypeScript, HTML/CSS, and modern CSS frameworks including Styled Components, Bootstrap, and Tailwind CSS. SME-level React engineer with a strong focus on component reusability, sca\n"
     ]
    }
   ],
   "source": [
    "print(my_resume[:500])  # Show the first 500 characters to make sure it loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96d2be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù Define the system's behavior\n",
    "system_prompt = (\n",
    "    \"You are a job assistant. I will give you a job listing, and you must compare it with my resume. \"\n",
    "    \"If it's a good match, summarize the job in markdown and say why it's a fit. If it's not, reply: 'Not a match.'\\n\\n\"\n",
    "    f\"My resume:\\n{my_resume}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51b290d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an analysis of the two job postings:\n",
      "\n",
      "**Job Posting 1: Fullstack Software Engineer at BlackCloak**\n",
      "\n",
      "* **Salary Range**: $67,500 - $105,000 per year\n",
      "* **Benefits**: Comprehensive medical, dental, and vision plans, flexible vacation plan, paid parental leave, company equity, home office stipend, and more.\n",
      "* **Remote Work Arrangement**: 100% remote company within the USA.\n",
      "* **Job Description**: The Fullstack Software Engineer will be responsible for designing, developing, and deploying web and mobile applications, as well as leading technical teams and mentoring junior engineers.\n",
      "\n",
      "**Job Posting 2: Fullstack Software Engineer at BlackCloak**\n",
      "\n",
      " Wait, it seems like there's an error in the job posting. I'll analyze the first one:\n",
      "\n",
      "* **Salary Range**: $68k - $105k per year\n",
      "* **Benefits**: Comprehensive medical, dental, and vision plans, flexible vacation plan, paid parental leave, company equity, home office stipend, and more.\n",
      "* **Remote Work Arrangement**: 100% remote company within the USA.\n",
      "* **Job Description**: The Fullstack Software Engineer will be responsible for designing, developing, and deploying web and mobile applications.\n",
      "\n",
      "**Key Takeaways**\n",
      "\n",
      "1. Both job postings are for Fullstack Software Engineers at BlackCloak.\n",
      "2. The salary ranges are slightly different ($68k - $105k vs $67,500 - $105,000).\n",
      "3. The benefits packages seem to be similar between the two postings (although the medical plan details are not specified).\n",
      "4. Both job postings offer 100% remote work arrangements, with no requirements for an office presence.\n",
      "5. The job descriptions highlight the importance of designing and developing high-quality web and mobile applications.\n",
      "\n",
      "**Which one is better?**\n",
      "\n",
      "It's difficult to say which one is better without knowing more about the company culture and the individual candidate preferences. However, both postings seem to offer competitive salaries and benefits packages for Fullstack Software Engineers. If you're interested in working remotely with a company that offers comprehensive benefits and a dynamic work environment, BlackCloak might be worth considering.\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Test the job finder on a real job listing\n",
    "test_url = \"https://remoteok.com/remote-javascript-jobs\"  #Replace with the url of the job listing you want to test\n",
    "\n",
    "# Initialize the page and build the prompt\n",
    "job_page = Job_Platform(test_url)\n",
    "user_prompt = user_prompt_for(job_page)\n",
    "\n",
    "# Call Ollama\n",
    "summary = ask_ollama(system_prompt, user_prompt)\n",
    "\n",
    "# Show result\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d5f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (job-copilot)",
   "language": "python",
   "name": "job-copilot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
