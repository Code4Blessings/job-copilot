# Imports

import os
import ollama
import requests
from bs4 import BeautifulSoup
from IPython.display import Markdown, display


import sys
print(sys.executable)


# Constants

OLLAMA_API = "http://localhost:11434/api/chat"
HEADERS = {"Content-Type": "application/json"}
MODEL = "llama3.2"


# Create a messages list using the same format that we used for OpenAI

messages = [
    {"role": "user", "content": "Say hello to Robin!"}
]


payload = {
        "model": MODEL,
        "messages": messages,
        "stream": False
    }


# Let's just make sure the model is loaded

!ollama pull llama3.2


response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)
print(response.json()['message']['content'])


# üèóÔ∏è Class to represent a job listing webpage

headers = {
 "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36"
}

class Job_Platform:
    def __init__(self, url):
        self.url = url
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.content, 'html.parser')
        self.title = soup.title.string if soup.title else "No title found"

        # Remove unwanted tags
        for irrelevant in soup.body(["script", "style", "img", "input"]):
            irrelevant.decompose()

        self.text = soup.body.get_text(separator="\n", strip=True)



# üí¨ Build a user prompt from the job listing
def user_prompt_for(job_listing):
    user_prompt = f"You are looking at a job listing titled: {job_listing.title}\n"
    user_prompt += "The contents of this listing are as follows. Please provide a short summary in markdown format. \
If there are job requirements, duties, or application instructions, highlight them:\n\n"
    user_prompt += job_listing.text
    return user_prompt



# üß† Send the user/system prompt to OpenAI
def ask_ollama(system_prompt, user_prompt, model=MODEL):
    response = ollama.chat(
        model=model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
    )
    return response['message']['content']



# üìÇ Load resume from file
with open("resume.txt", "r") as file:
    my_resume = file.read()



print(my_resume[:500])  # Show the first 500 characters to make sure it loaded



# üìù Define the system's behavior
system_prompt = (
    "You are a job assistant. I will give you a job listing, and you must compare it with my resume. "
    "If it's a good match, summarize the job in markdown and say why it's a fit. If it's not, reply: 'Not a match.'\n\n"
    f"My resume:\n{my_resume}"
)




# üîÅ List of job board URLs to scrape
job_urls = [
    "https://www.dice.com/jobs?q=software+development&location=Georgia%2C+USA&latitude=32.1574351&longitude=-82.90712300000001&countryCode=US&locationPrecision=State&adminDistrictCode=GA&radiusUnit=mi",
    "https://www.indeed.com/jobs?q=software+developer&l=Lawrenceville%2C+GA&from=searchOnHP%2Cwhatautocomplete%2CwhatautocompleteSourceStandard&vjk=b655bdf9f48950ef"
]

# üí° Optional: Store all summaries in a list for later use
job_summaries = []

# üß† Loop through each job URL
for idx, url in enumerate(job_urls, start=1):
    try:
        print(f"\nüîç [{idx}] Scraping job listing from:\n{url}")

        # Scrape and process the page
        job_page = Job_Platform(url)
        user_prompt = user_prompt_for(job_page)

        # Ask Ollama for a summary
        summary = ask_ollama(system_prompt, user_prompt)

        # Print or collect the summary
        print(f"\nüìù Summary from {url}:\n")
        print(summary)

        # Optional: Save for later
        job_summaries.append({
            "url": url,
            "title": job_page.title,
            "summary": summary
        })

    except Exception as e:
        print(f"‚ùå Failed to process {url}: {e}")




